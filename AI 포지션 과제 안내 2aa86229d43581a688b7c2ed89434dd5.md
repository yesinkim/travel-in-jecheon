# AI 포지션 과제 안내

# 과제 개요

먼저, 당사에 입사지원을 해주시고, 사전과제에 응해주셔서 감사의 말씀드립니다.

본 과제는 지원자의 **RAG(Retrieval-Augmented Generation)** 시스템 구축 능력과 **LLM Fine-tuning** 이해도를 평가하기 위한 실습 과제입니다.

---

## 과제 목표

제공된 PDF 문서를 기반으로 RAG 시스템을 구축하고, RAG Fine-tuning 개념에 대한 이해를 실제 구현을 통해 보여주시기 바랍니다.

---

## 제출 항목 체크리스트

- [ ]  Hugging Face Dataset 링크 (RAG 학습/평가 데이터셋)
- [ ]  Hugging Face Model 링크 (Fine-tuned 모델)
- [ ]  구현 코드 (GitHub 링크)
- [ ]  결과 보고서 (PDF 또는 Markdown)
    - [ ]  데이터 구축에 대한 설명
    - [ ]  LLM과 embedding 모델의 선정에 대한 설명
    - [ ]  Baseline vs Fine-tuned 성능 비교 결과(스크린샷 포함)
    - [ ]  성능 평가 결과에 대한 설명

---

## 과제 내용

### 1. RAG 데이터셋 구축

- 제공된 PDF 문서를 활용하여 RAG 시스템용 학습 데이터셋을 구축하세요.
- **요구사항:** 구축한 데이터셋을 Hugging Face Dataset으로 업로드

### 2. Baseline 모델 평가 (Fine-tuning 전)

오픈소스 LLM을 선택하여 구축한 RAG 데이터셋으로 평가를 수행하세요.

**요구사항:**

- 오픈소스 모델 선택 (예: Llama, Qwen, Gemma, Phi 등)
- 구축한 테스트셋으로 inference 수행

**평가 메트릭 :**

- 어떤 평가 매트릭을 써야하는지 고민하여 선정하고 그 이유를 설명하세요.

### 3. RAG Fine-tuning 수행

구축한 데이터셋으로 선택한 모델을 Fine-tuning하세요.

**요구사항:**

- RAG 태스크에 특화된 Fine-tuning 수행
- Fine-tuned 모델을 Hugging Face Model Hub에 업로드

### 4. Fine-tuned 모델 평가 및 비교

Fine-tuned 모델로 동일한 테스트셋에 대해 평가하고 Baseline과 비교하세요.

**요구사항:**

- Baseline과 동일한 평가 메트릭 사용
- Fine-tuning 전후 성능 비교 분석

**비교 분석 항목:**

- 각 메트릭별 성능 변화
- 개선된 부분 및 한계점
- 실패 사례 분석 및 원인 파악

---

## 제출 방법

### 1. Hugging Face 업로드

**데이터셋:**

- 구축한 RAG 데이터셋을 Hugging Face Dataset으로 업로드
- 형식: `https://huggingface.co/datasets/[your-username]/[dataset-name]`

**모델 (옵션 A 선택 시):**

- Fine-tuned 모델을 Hugging Face Model Hub에 업로드
- 형식: `https://huggingface.co/[your-username]/[model-name]`

### 2. 결과 보고서 작성

다음 내용을 포함한 보고서를 PDF로 제출하세요

### 보고서 구성

**1. 프로젝트 개요**

- 과제 이해 및 접근 방식
- 사용한 기술 스택 및 환경

**2. RAG 데이터셋 구축 과정**

- PDF 전처리 방법
- 데이터 분석

**3. Baseline 모델 평가**

- 선택한 오픈소스 모델 및 선정 이유
- 평가 메트릭 선정 이유
- Baseline 성능 결과

**4. RAG Fine-tuning 수행**

- Fine-tuning 전략 및 방법론
- 하이퍼파라미터 설정 및 근거
- 학습 과정 및 Loss 그래프
- 직면한 문제와 해결 방법

**5. Fine-tuned 모델 평가 및 비교**

- Fine-tuned 모델 성능 결과
- Baseline vs Fine-tuned 성능 비교 (표 및 그래프)
- 각 메트릭별 성능 변화 분석
- 정성적 평가: 답변 예시 비교 (최소 3개 이상)
- 개선된 부분 및 한계점
- 실패 사례 분석

**6. 구현 코드 설명**

- 핵심 코드 설명
- 사용한 라이브러리 및 프레임워크

**7. 결론 및 향후 개선 방안**

- 프로젝트 요약
- 인사이트 및 배운 점
- 추가 개선 아이디어

---

## 제출 기한

**과제 제출 기한:** 

---

## 참고 사항

- 데이터 구축 시 LLM 활용 가능 (GPT, Claude 등)
- GPU 리소스는 런팟 크래딧 및 크래딧 사용방법을 전달드리오니 런팟 이용
- 학습 데이터와 평가 데이터는 반드시 분리
- 모든 코드와 데이터는 공개 가능한 형태로 제출

---

## 문의사항

과제 수행 중 질문이나 기술적 문제가 발생하면 `dasol@goodganglabs.com`로 문의해 주시기 바랍니다.

---

## 첨부 파일

- `[PDF 파일명].pdf` - RAG 시스템 구축에 사용할 문서
    
    [제천시관광정보책자.pdf](AI%20%ED%8F%AC%EC%A7%80%EC%85%98%20%EA%B3%BC%EC%A0%9C%20%EC%95%88%EB%82%B4/%E1%84%8C%E1%85%A6%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%89%E1%85%B5%E1%84%80%E1%85%AA%E1%86%AB%E1%84%80%E1%85%AA%E1%86%BC%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A9%E1%84%8E%E1%85%A2%E1%86%A8%E1%84%8C%E1%85%A1.pdf)
    
- `런팟크래딧` - “c1w0wzucm2khx7qk0br9”
- `런팟크래딧 사용방법`
    
    [Runpod설정방법.pdf](AI%20%ED%8F%AC%EC%A7%80%EC%85%98%20%EA%B3%BC%EC%A0%9C%20%EC%95%88%EB%82%B4/Runpod%E1%84%89%E1%85%A5%E1%86%AF%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A1%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8.pdf)
    

---

## 참고자료

https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO
https://www.databricks.com/kr/blog/improving-retrieval-and-rag-embedding-model-finetuning
https://arxiv.org/pdf/2505.10792 -> 모델 파인튜닝 방법 참고
https://colab.research.google.com/github/ashishpatel26/LLM-Finetuning/blob/main/2.Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.ipynb#scrollTo=_NAQWYv9eRnM -> llama 참고 파인튜닝

### LLM 성능 비교
![image.png](image.png)
https://wandb.ai/wandb-korea/llm-leaderboard3/reports/Horangi-W-B-Korean-LLM-Leaderboard-3--Vmlldzo5NTM4MjU0
https://ariz1623.tistory.com/374

### embedding leaderboard
https://huggingface.co/spaces/mteb/leaderboard # embedding leaderboard